{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXqISpAMMr-U"
      },
      "outputs": [],
      "source": [
        "from keras.datasets  import cifar10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5RvoXAKNxr_"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "creoI3gNMvR8"
      },
      "outputs": [],
      "source": [
        " (x_train,y_train),(x_test,y_test)=cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ar88Kb_7NNFh",
        "outputId": "a6d7327b-e54c-4caf-9701-5e88be7e4eda"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3uJi4PMNSMi"
      },
      "outputs": [],
      "source": [
        "single_image=x_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-iDBn3xNeyu",
        "outputId": "9fb9c5e6-fe36-4744-e13a-55691e28a98a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 59,  62,  63],\n",
              "        [ 43,  46,  45],\n",
              "        [ 50,  48,  43],\n",
              "        ...,\n",
              "        [158, 132, 108],\n",
              "        [152, 125, 102],\n",
              "        [148, 124, 103]],\n",
              "\n",
              "       [[ 16,  20,  20],\n",
              "        [  0,   0,   0],\n",
              "        [ 18,   8,   0],\n",
              "        ...,\n",
              "        [123,  88,  55],\n",
              "        [119,  83,  50],\n",
              "        [122,  87,  57]],\n",
              "\n",
              "       [[ 25,  24,  21],\n",
              "        [ 16,   7,   0],\n",
              "        [ 49,  27,   8],\n",
              "        ...,\n",
              "        [118,  84,  50],\n",
              "        [120,  84,  50],\n",
              "        [109,  73,  42]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[208, 170,  96],\n",
              "        [201, 153,  34],\n",
              "        [198, 161,  26],\n",
              "        ...,\n",
              "        [160, 133,  70],\n",
              "        [ 56,  31,   7],\n",
              "        [ 53,  34,  20]],\n",
              "\n",
              "       [[180, 139,  96],\n",
              "        [173, 123,  42],\n",
              "        [186, 144,  30],\n",
              "        ...,\n",
              "        [184, 148,  94],\n",
              "        [ 97,  62,  34],\n",
              "        [ 83,  53,  34]],\n",
              "\n",
              "       [[177, 144, 116],\n",
              "        [168, 129,  94],\n",
              "        [179, 142,  87],\n",
              "        ...,\n",
              "        [216, 184, 140],\n",
              "        [151, 118,  84],\n",
              "        [123,  92,  72]]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ],
      "source": [
        "single_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNHIIb7dNh57",
        "outputId": "b4fb5e52-36b1-4d07-e309-aaa2deae0cec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ],
      "source": [
        "single_image.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "9V7zo6nHNj1G",
        "outputId": "2ac81a27-1608-4dcd-ba82-6cc3edcf68ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f21278e02e0>"
            ]
          },
          "metadata": {},
          "execution_count": 95
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.imshow(single_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvhrbtNfNnZZ",
        "outputId": "9227cf1d-2d4f-4e2a-9371-b7276c872bd6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6],\n",
              "       [9],\n",
              "       [9],\n",
              "       ...,\n",
              "       [9],\n",
              "       [1],\n",
              "       [1]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZDSAW6tOFcZ",
        "outputId": "a33491aa-d103-4bf4-d034-9807bd5cc7a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3],\n",
              "       [8],\n",
              "       [8],\n",
              "       ...,\n",
              "       [5],\n",
              "       [1],\n",
              "       [7]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "source": [
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PatNHg2KOHOa"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5CoGmuLOKjr",
        "outputId": "2bbb01e6-d5f0-4a2d-8e6a-63b4fd0cd25f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9sAffL5ON68",
        "outputId": "dcba32d7-020d-4253-b0e9-62d01fb81b23"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ],
      "source": [
        "y_example=to_categorical(y_train)\n",
        "y_example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1TvocFxOZqA"
      },
      "outputs": [],
      "source": [
        "# Normalize pixel values to be between 0 and 1\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Convert class vectors to binary class matrices\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "ufKOz_aRO6A3",
        "outputId": "f7a8530b-3a3d-417a-d085-a85a538e13bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"# Build a simple CNN model\\nmodel = models.Sequential()\\nmodel.add(layers.Conv2D(44, (3, 3), activation='relu', input_shape=(32, 32, 3)))\\nmodel.add(layers.Conv2D(44, (3, 3), activation='relu', input_shape=(32, 32, 3)))\\nmodel.add(layers.MaxPooling2D((2, 2)))\\nmodel.add(layers.Conv2D(70, (3, 3), activation='relu'))\\nmodel.add(layers.Conv2D(44, (3, 3), activation='relu', input_shape=(32, 32, 3)))\\nmodel.add(layers.Flatten())\\nmodel.add(layers.Dense(64, activation='relu'))\\nmodel.add(layers.Dense(64, activation='relu'))\\nmodel.add(layers.Dense(64, activation='relu'))\\nmodel.add(layers.Dense(64, activation='relu'))\\nmodel.add(layers.Dense(10, activation='softmax'))\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 102
        }
      ],
      "source": [
        "'''# Build a simple CNN model\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(44, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(layers.Conv2D(44, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(70, (3, 3), activation='relu'))\n",
        "model.add(layers.Conv2D(44, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))'''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MODEL 1"
      ],
      "metadata": {
        "id": "_ITLi-LRw7G5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEmzm2XnaDSL"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# Assuming input_shape is defined earlier in your code\n",
        "\n",
        "model = models.Sequential()\n",
        "\n",
        "# Convolutional Layers\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Flatten the output for fully connected layers\n",
        "model.add(Flatten())\n",
        "\n",
        "# Fully Connected Layers\n",
        "model.add(Dense(units=512, activation='relu'))\n",
        "model.add(Dense(units=128, activation='relu'))\n",
        "model.add(Dense(units=32, activation='relu'))\n",
        "model.add(Dense(units=10, activation='relu'))\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(units=10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKGIkLEKO85p"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jY8KpXwPGpu",
        "outputId": "a664e634-75c9-445a-98b9-2daf9aa4046b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1563/1563 [==============================] - 13s 6ms/step - loss: 0.0523 - accuracy: 0.9850\n",
            "Epoch 2/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0408 - accuracy: 0.9876\n",
            "Epoch 3/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0452 - accuracy: 0.9872\n",
            "Epoch 4/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0423 - accuracy: 0.9877\n",
            "Epoch 5/100\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0475 - accuracy: 0.9866\n",
            "Epoch 6/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0420 - accuracy: 0.9875\n",
            "Epoch 7/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0434 - accuracy: 0.9874\n",
            "Epoch 8/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0344 - accuracy: 0.9900\n",
            "Epoch 9/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0429 - accuracy: 0.9881\n",
            "Epoch 10/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0400 - accuracy: 0.9882\n",
            "Epoch 11/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0365 - accuracy: 0.9894\n",
            "Epoch 12/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0369 - accuracy: 0.9887\n",
            "Epoch 13/100\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0406 - accuracy: 0.9881\n",
            "Epoch 14/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0373 - accuracy: 0.9895\n",
            "Epoch 15/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0389 - accuracy: 0.9895\n",
            "Epoch 16/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0363 - accuracy: 0.9906\n",
            "Epoch 17/100\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0379 - accuracy: 0.9894\n",
            "Epoch 18/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0332 - accuracy: 0.9908\n",
            "Epoch 19/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0351 - accuracy: 0.9906\n",
            "Epoch 20/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0379 - accuracy: 0.9894\n",
            "Epoch 21/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0322 - accuracy: 0.9906\n",
            "Epoch 22/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0266 - accuracy: 0.9921\n",
            "Epoch 23/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0412 - accuracy: 0.9888\n",
            "Epoch 24/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.0320 - accuracy: 0.9908\n",
            "Epoch 25/100\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0309 - accuracy: 0.9915\n",
            "Epoch 26/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0342 - accuracy: 0.9907\n",
            "Epoch 27/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0317 - accuracy: 0.9915\n",
            "Epoch 28/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0298 - accuracy: 0.9916\n",
            "Epoch 29/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0331 - accuracy: 0.9912\n",
            "Epoch 30/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.0412 - accuracy: 0.9900\n",
            "Epoch 31/100\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0297 - accuracy: 0.9923\n",
            "Epoch 32/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0281 - accuracy: 0.9925\n",
            "Epoch 33/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0329 - accuracy: 0.9917\n",
            "Epoch 34/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0320 - accuracy: 0.9916\n",
            "Epoch 35/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0316 - accuracy: 0.9916\n",
            "Epoch 36/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0320 - accuracy: 0.9919\n",
            "Epoch 37/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0319 - accuracy: 0.9920\n",
            "Epoch 38/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0297 - accuracy: 0.9922\n",
            "Epoch 39/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0356 - accuracy: 0.9912\n",
            "Epoch 40/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0269 - accuracy: 0.9935\n",
            "Epoch 41/100\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0288 - accuracy: 0.9925\n",
            "Epoch 42/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0301 - accuracy: 0.9922\n",
            "Epoch 43/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0260 - accuracy: 0.9937\n",
            "Epoch 44/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0357 - accuracy: 0.9914\n",
            "Epoch 45/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0299 - accuracy: 0.9928\n",
            "Epoch 46/100\n",
            "1563/1563 [==============================] - 13s 9ms/step - loss: 0.0335 - accuracy: 0.9918\n",
            "Epoch 47/100\n",
            "1563/1563 [==============================] - 13s 9ms/step - loss: 0.0304 - accuracy: 0.9929\n",
            "Epoch 48/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0277 - accuracy: 0.9930\n",
            "Epoch 49/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0297 - accuracy: 0.9926\n",
            "Epoch 50/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0302 - accuracy: 0.9924\n",
            "Epoch 51/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.0293 - accuracy: 0.9929\n",
            "Epoch 52/100\n",
            "1563/1563 [==============================] - 13s 9ms/step - loss: 0.0344 - accuracy: 0.9920\n",
            "Epoch 53/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0287 - accuracy: 0.9922\n",
            "Epoch 54/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0319 - accuracy: 0.9917\n",
            "Epoch 55/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0235 - accuracy: 0.9941\n",
            "Epoch 56/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0330 - accuracy: 0.9923\n",
            "Epoch 57/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0290 - accuracy: 0.9929\n",
            "Epoch 58/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0253 - accuracy: 0.9941\n",
            "Epoch 59/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0276 - accuracy: 0.9936\n",
            "Epoch 60/100\n",
            "1563/1563 [==============================] - 13s 9ms/step - loss: 0.0277 - accuracy: 0.9933\n",
            "Epoch 61/100\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0358 - accuracy: 0.9920\n",
            "Epoch 62/100\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.0272 - accuracy: 0.9936\n",
            "Epoch 63/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0282 - accuracy: 0.9939\n",
            "Epoch 64/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0302 - accuracy: 0.9931\n",
            "Epoch 65/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0284 - accuracy: 0.9936\n",
            "Epoch 66/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0279 - accuracy: 0.9934\n",
            "Epoch 67/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0239 - accuracy: 0.9944\n",
            "Epoch 68/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0225 - accuracy: 0.9952\n",
            "Epoch 69/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0331 - accuracy: 0.9926\n",
            "Epoch 70/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0237 - accuracy: 0.9945\n",
            "Epoch 71/100\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 0.0316 - accuracy: 0.9927\n",
            "Epoch 72/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.0294 - accuracy: 0.9937\n",
            "Epoch 73/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0472 - accuracy: 0.9894\n",
            "Epoch 74/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0229 - accuracy: 0.9947\n",
            "Epoch 75/100\n",
            "1563/1563 [==============================] - 13s 9ms/step - loss: 0.0262 - accuracy: 0.9941\n",
            "Epoch 76/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0230 - accuracy: 0.9952\n",
            "Epoch 77/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0367 - accuracy: 0.9915\n",
            "Epoch 78/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0241 - accuracy: 0.9951\n",
            "Epoch 79/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0208 - accuracy: 0.9951\n",
            "Epoch 80/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0315 - accuracy: 0.9925\n",
            "Epoch 81/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0278 - accuracy: 0.9942\n",
            "Epoch 82/100\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.0219 - accuracy: 0.9951\n",
            "Epoch 83/100\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 0.0313 - accuracy: 0.9932\n",
            "Epoch 84/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0216 - accuracy: 0.9950\n",
            "Epoch 85/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0304 - accuracy: 0.9936\n",
            "Epoch 86/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0247 - accuracy: 0.9946\n",
            "Epoch 87/100\n",
            "1563/1563 [==============================] - 13s 9ms/step - loss: 0.0289 - accuracy: 0.9937\n",
            "Epoch 88/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0206 - accuracy: 0.9956\n",
            "Epoch 89/100\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 0.0345 - accuracy: 0.9927\n",
            "Epoch 90/100\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 0.0210 - accuracy: 0.9951\n",
            "Epoch 91/100\n",
            "1563/1563 [==============================] - 13s 9ms/step - loss: 0.0348 - accuracy: 0.9927\n",
            "Epoch 92/100\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0306 - accuracy: 0.9937\n",
            "Epoch 93/100\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.0273 - accuracy: 0.9943\n",
            "Epoch 94/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0241 - accuracy: 0.9948\n",
            "Epoch 95/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0289 - accuracy: 0.9946\n",
            "Epoch 96/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0173 - accuracy: 0.9957\n",
            "Epoch 97/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0286 - accuracy: 0.9938\n",
            "Epoch 98/100\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0241 - accuracy: 0.9947\n",
            "Epoch 99/100\n",
            "1563/1563 [==============================] - 13s 9ms/step - loss: 0.0280 - accuracy: 0.9942\n",
            "Epoch 100/100\n",
            "1563/1563 [==============================] - 13s 9ms/step - loss: 0.0354 - accuracy: 0.9921\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f212775f160>"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ],
      "source": [
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8nvvhgZPH9l"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNYfQrgrPJex",
        "outputId": "d492aa65-3fa8-4222-fc80-7758cde6dc00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_18 (Conv2D)          (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 28, 28, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPoolin  (None, 14, 14, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 12, 12, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 10, 10, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPoolin  (None, 5, 5, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 1600)              0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 512)               819712    \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 128)               65664     \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 32)                4128      \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 10)                330       \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 10)                110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 955512 (3.64 MB)\n",
            "Trainable params: 955512 (3.64 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ghvn4ztXc-F",
        "outputId": "8fee6743-a0d9-4d38-e52d-6f70be25be7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5000/5000 [==============================] - 25s 5ms/step - loss: 0.8108 - accuracy: 0.7428\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8107507228851318, 0.7427999973297119]"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ],
      "source": [
        "model.evaluate(x_test,y_test,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RM8LuheeSCFN",
        "outputId": "10271458-5004-453d-e886-f6e02846c1b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.75      0.75      1000\n",
            "           1       0.87      0.86      0.86      1000\n",
            "           2       0.62      0.59      0.61      1000\n",
            "           3       0.56      0.51      0.54      1000\n",
            "           4       0.65      0.73      0.69      1000\n",
            "           5       0.61      0.65      0.63      1000\n",
            "           6       0.79      0.82      0.81      1000\n",
            "           7       0.79      0.76      0.77      1000\n",
            "           8       0.84      0.82      0.83      1000\n",
            "           9       0.83      0.82      0.83      1000\n",
            "\n",
            "    accuracy                           0.73     10000\n",
            "   macro avg       0.73      0.73      0.73     10000\n",
            "weighted avg       0.73      0.73      0.73     10000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Evaluate the model on the test data\n",
        "predictions = model.predict(x_test)\n",
        "predicted_labels = tf.argmax(predictions, axis=1)\n",
        "true_labels = tf.argmax(y_test, axis=1)\n",
        "\n",
        "# Classification Report\n",
        "report = classification_report(true_labels, predicted_labels, target_names=[str(i) for i in range(10)])\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MODEL  2\n"
      ],
      "metadata": {
        "id": "v7agp3r_w-Ty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Example architecture (modify as needed)\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))  # Add dropout layer\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))  # Add dropout layer\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model with adjusted learning rate and other hyperparameters\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model for more epochs\n",
        "model.fit(x_train, y_train, epochs=200, batch_size=32, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFOsFkoenfbQ",
        "outputId": "55d9540d-b37d-493e-dffd-8332c851b5d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 1.6443 - accuracy: 0.3988 - val_loss: 1.2601 - val_accuracy: 0.5692\n",
            "Epoch 2/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 1.2659 - accuracy: 0.5527 - val_loss: 1.0836 - val_accuracy: 0.6258\n",
            "Epoch 3/200\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 1.1067 - accuracy: 0.6187 - val_loss: 0.9892 - val_accuracy: 0.6557\n",
            "Epoch 4/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 1.0058 - accuracy: 0.6550 - val_loss: 0.9602 - val_accuracy: 0.6672\n",
            "Epoch 5/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.9107 - accuracy: 0.6875 - val_loss: 0.8860 - val_accuracy: 0.6997\n",
            "Epoch 6/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.8343 - accuracy: 0.7157 - val_loss: 0.9022 - val_accuracy: 0.6862\n",
            "Epoch 7/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.7622 - accuracy: 0.7409 - val_loss: 0.9298 - val_accuracy: 0.6860\n",
            "Epoch 8/200\n",
            "1250/1250 [==============================] - 12s 10ms/step - loss: 0.7033 - accuracy: 0.7597 - val_loss: 0.8631 - val_accuracy: 0.7098\n",
            "Epoch 9/200\n",
            "1250/1250 [==============================] - 12s 10ms/step - loss: 0.6500 - accuracy: 0.7789 - val_loss: 0.8583 - val_accuracy: 0.7153\n",
            "Epoch 10/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.6029 - accuracy: 0.7930 - val_loss: 0.8521 - val_accuracy: 0.7177\n",
            "Epoch 11/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.5552 - accuracy: 0.8097 - val_loss: 0.9755 - val_accuracy: 0.6891\n",
            "Epoch 12/200\n",
            "1250/1250 [==============================] - 9s 8ms/step - loss: 0.5245 - accuracy: 0.8189 - val_loss: 0.8903 - val_accuracy: 0.7187\n",
            "Epoch 13/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.4947 - accuracy: 0.8307 - val_loss: 0.9138 - val_accuracy: 0.7200\n",
            "Epoch 14/200\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.4635 - accuracy: 0.8415 - val_loss: 0.9377 - val_accuracy: 0.7244\n",
            "Epoch 15/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.4276 - accuracy: 0.8558 - val_loss: 0.9846 - val_accuracy: 0.7188\n",
            "Epoch 16/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.4168 - accuracy: 0.8582 - val_loss: 0.9782 - val_accuracy: 0.7178\n",
            "Epoch 17/200\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.3907 - accuracy: 0.8696 - val_loss: 1.0180 - val_accuracy: 0.7182\n",
            "Epoch 18/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.3741 - accuracy: 0.8738 - val_loss: 1.0502 - val_accuracy: 0.7186\n",
            "Epoch 19/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.3621 - accuracy: 0.8785 - val_loss: 1.0376 - val_accuracy: 0.7192\n",
            "Epoch 20/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.3527 - accuracy: 0.8820 - val_loss: 1.0587 - val_accuracy: 0.7151\n",
            "Epoch 21/200\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.3291 - accuracy: 0.8889 - val_loss: 1.0823 - val_accuracy: 0.7243\n",
            "Epoch 22/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.3145 - accuracy: 0.8950 - val_loss: 1.1384 - val_accuracy: 0.7183\n",
            "Epoch 23/200\n",
            "1250/1250 [==============================] - 12s 10ms/step - loss: 0.3092 - accuracy: 0.8960 - val_loss: 1.1243 - val_accuracy: 0.7175\n",
            "Epoch 24/200\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.2973 - accuracy: 0.9000 - val_loss: 1.1041 - val_accuracy: 0.7209\n",
            "Epoch 25/200\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.2847 - accuracy: 0.9050 - val_loss: 1.1223 - val_accuracy: 0.7192\n",
            "Epoch 26/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.2792 - accuracy: 0.9069 - val_loss: 1.1411 - val_accuracy: 0.7233\n",
            "Epoch 27/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.2696 - accuracy: 0.9106 - val_loss: 1.1347 - val_accuracy: 0.7173\n",
            "Epoch 28/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.2720 - accuracy: 0.9091 - val_loss: 1.1609 - val_accuracy: 0.7217\n",
            "Epoch 29/200\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.2546 - accuracy: 0.9156 - val_loss: 1.2142 - val_accuracy: 0.7182\n",
            "Epoch 30/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.2503 - accuracy: 0.9170 - val_loss: 1.2695 - val_accuracy: 0.7161\n",
            "Epoch 31/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.2410 - accuracy: 0.9227 - val_loss: 1.4089 - val_accuracy: 0.7021\n",
            "Epoch 32/200\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.2367 - accuracy: 0.9211 - val_loss: 1.2510 - val_accuracy: 0.7172\n",
            "Epoch 33/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.2413 - accuracy: 0.9219 - val_loss: 1.2539 - val_accuracy: 0.7258\n",
            "Epoch 34/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.2265 - accuracy: 0.9260 - val_loss: 1.2685 - val_accuracy: 0.7185\n",
            "Epoch 35/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.2180 - accuracy: 0.9284 - val_loss: 1.3054 - val_accuracy: 0.7187\n",
            "Epoch 36/200\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.2312 - accuracy: 0.9249 - val_loss: 1.2894 - val_accuracy: 0.7166\n",
            "Epoch 37/200\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.2153 - accuracy: 0.9295 - val_loss: 1.3164 - val_accuracy: 0.7080\n",
            "Epoch 38/200\n",
            "1250/1250 [==============================] - 13s 10ms/step - loss: 0.2158 - accuracy: 0.9311 - val_loss: 1.2665 - val_accuracy: 0.7218\n",
            "Epoch 39/200\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.2119 - accuracy: 0.9321 - val_loss: 1.3507 - val_accuracy: 0.7162\n",
            "Epoch 40/200\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.2043 - accuracy: 0.9359 - val_loss: 1.3033 - val_accuracy: 0.7119\n",
            "Epoch 41/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.1957 - accuracy: 0.9376 - val_loss: 1.3732 - val_accuracy: 0.7187\n",
            "Epoch 42/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.2034 - accuracy: 0.9354 - val_loss: 1.3576 - val_accuracy: 0.7248\n",
            "Epoch 43/200\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.2032 - accuracy: 0.9356 - val_loss: 1.3942 - val_accuracy: 0.7172\n",
            "Epoch 44/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.1928 - accuracy: 0.9388 - val_loss: 1.3350 - val_accuracy: 0.7251\n",
            "Epoch 45/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.1945 - accuracy: 0.9365 - val_loss: 1.4231 - val_accuracy: 0.7180\n",
            "Epoch 46/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.1847 - accuracy: 0.9410 - val_loss: 1.4914 - val_accuracy: 0.7202\n",
            "Epoch 47/200\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.1943 - accuracy: 0.9380 - val_loss: 1.3670 - val_accuracy: 0.7241\n",
            "Epoch 48/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.1844 - accuracy: 0.9420 - val_loss: 1.4430 - val_accuracy: 0.7172\n",
            "Epoch 49/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.1773 - accuracy: 0.9436 - val_loss: 1.4489 - val_accuracy: 0.7212\n",
            "Epoch 50/200\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.1882 - accuracy: 0.9409 - val_loss: 1.4639 - val_accuracy: 0.7223\n",
            "Epoch 51/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.1741 - accuracy: 0.9439 - val_loss: 1.4660 - val_accuracy: 0.7174\n",
            "Epoch 52/200\n",
            "1250/1250 [==============================] - 12s 9ms/step - loss: 0.1816 - accuracy: 0.9454 - val_loss: 1.4496 - val_accuracy: 0.7200\n",
            "Epoch 53/200\n",
            "1250/1250 [==============================] - 12s 9ms/step - loss: 0.1770 - accuracy: 0.9436 - val_loss: 1.5563 - val_accuracy: 0.7120\n",
            "Epoch 54/200\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.1677 - accuracy: 0.9471 - val_loss: 1.4436 - val_accuracy: 0.7194\n",
            "Epoch 55/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.1671 - accuracy: 0.9488 - val_loss: 1.5816 - val_accuracy: 0.7184\n",
            "Epoch 56/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.1671 - accuracy: 0.9481 - val_loss: 1.6784 - val_accuracy: 0.7172\n",
            "Epoch 57/200\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.1694 - accuracy: 0.9469 - val_loss: 1.5113 - val_accuracy: 0.7189\n",
            "Epoch 58/200\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.1708 - accuracy: 0.9451 - val_loss: 1.5110 - val_accuracy: 0.7204\n",
            "Epoch 59/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.1634 - accuracy: 0.9490 - val_loss: 1.5477 - val_accuracy: 0.7183\n",
            "Epoch 60/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.1622 - accuracy: 0.9485 - val_loss: 1.4620 - val_accuracy: 0.7175\n",
            "Epoch 61/200\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.1655 - accuracy: 0.9501 - val_loss: 1.5275 - val_accuracy: 0.7208\n",
            "Epoch 62/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.1635 - accuracy: 0.9501 - val_loss: 1.6104 - val_accuracy: 0.7216\n",
            "Epoch 63/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.1629 - accuracy: 0.9491 - val_loss: 1.8138 - val_accuracy: 0.7149\n",
            "Epoch 64/200\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.1538 - accuracy: 0.9517 - val_loss: 1.5861 - val_accuracy: 0.7137\n",
            "Epoch 65/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.1578 - accuracy: 0.9515 - val_loss: 1.7083 - val_accuracy: 0.7185\n",
            "Epoch 66/200\n",
            "1250/1250 [==============================] - 9s 8ms/step - loss: 0.1567 - accuracy: 0.9506 - val_loss: 1.6760 - val_accuracy: 0.7200\n",
            "Epoch 67/200\n",
            "1250/1250 [==============================] - 12s 10ms/step - loss: 0.1635 - accuracy: 0.9500 - val_loss: 1.6326 - val_accuracy: 0.7203\n",
            "Epoch 68/200\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.1467 - accuracy: 0.9549 - val_loss: 1.6769 - val_accuracy: 0.7063\n",
            "Epoch 69/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.1535 - accuracy: 0.9526 - val_loss: 1.6696 - val_accuracy: 0.7178\n",
            "Epoch 70/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.1496 - accuracy: 0.9540 - val_loss: 1.6304 - val_accuracy: 0.7124\n",
            "Epoch 71/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.1610 - accuracy: 0.9516 - val_loss: 1.6956 - val_accuracy: 0.7213\n",
            "Epoch 72/200\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.1514 - accuracy: 0.9544 - val_loss: 1.5922 - val_accuracy: 0.7224\n",
            "Epoch 73/200\n",
            "1250/1250 [==============================] - 9s 8ms/step - loss: 0.1500 - accuracy: 0.9541 - val_loss: 1.6137 - val_accuracy: 0.7216\n",
            "Epoch 74/200\n",
            "1250/1250 [==============================] - 9s 8ms/step - loss: 0.1484 - accuracy: 0.9533 - val_loss: 1.7434 - val_accuracy: 0.7162\n",
            "Epoch 75/200\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.1458 - accuracy: 0.9566 - val_loss: 1.6937 - val_accuracy: 0.7114\n",
            "Epoch 76/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.1433 - accuracy: 0.9559 - val_loss: 1.7614 - val_accuracy: 0.7206\n",
            "Epoch 77/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.1491 - accuracy: 0.9556 - val_loss: 1.5579 - val_accuracy: 0.7144\n",
            "Epoch 78/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.1513 - accuracy: 0.9529 - val_loss: 1.7622 - val_accuracy: 0.7203\n",
            "Epoch 79/200\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.1423 - accuracy: 0.9553 - val_loss: 1.7296 - val_accuracy: 0.7228\n",
            "Epoch 80/200\n",
            "1250/1250 [==============================] - 9s 8ms/step - loss: 0.1479 - accuracy: 0.9558 - val_loss: 1.7089 - val_accuracy: 0.7161\n",
            "Epoch 81/200\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.1459 - accuracy: 0.9558 - val_loss: 1.7277 - val_accuracy: 0.7224\n",
            "Epoch 82/200\n",
            "1250/1250 [==============================] - 13s 11ms/step - loss: 0.1473 - accuracy: 0.9548 - val_loss: 1.6402 - val_accuracy: 0.7277\n",
            "Epoch 83/200\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.1477 - accuracy: 0.9550 - val_loss: 1.7348 - val_accuracy: 0.7192\n",
            "Epoch 84/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.1427 - accuracy: 0.9562 - val_loss: 1.7586 - val_accuracy: 0.7164\n",
            "Epoch 85/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.1431 - accuracy: 0.9570 - val_loss: 1.7181 - val_accuracy: 0.7206\n",
            "Epoch 86/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.1463 - accuracy: 0.9557 - val_loss: 1.7530 - val_accuracy: 0.7242\n",
            "Epoch 87/200\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.1432 - accuracy: 0.9571 - val_loss: 1.7546 - val_accuracy: 0.7170\n",
            "Epoch 88/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.1399 - accuracy: 0.9578 - val_loss: 1.6699 - val_accuracy: 0.7231\n",
            "Epoch 89/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.1374 - accuracy: 0.9585 - val_loss: 1.8452 - val_accuracy: 0.7157\n",
            "Epoch 90/200\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.1382 - accuracy: 0.9577 - val_loss: 1.7810 - val_accuracy: 0.7137\n",
            "Epoch 91/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.1343 - accuracy: 0.9589 - val_loss: 1.7694 - val_accuracy: 0.7175\n",
            "Epoch 92/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.1364 - accuracy: 0.9588 - val_loss: 1.9605 - val_accuracy: 0.7121\n",
            "Epoch 93/200\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.1408 - accuracy: 0.9602 - val_loss: 1.7889 - val_accuracy: 0.7155\n",
            "Epoch 94/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.1417 - accuracy: 0.9584 - val_loss: 1.7797 - val_accuracy: 0.7230\n",
            "Epoch 95/200\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.1403 - accuracy: 0.9581 - val_loss: 1.8106 - val_accuracy: 0.7255\n",
            "Epoch 96/200\n",
            "1250/1250 [==============================] - 14s 11ms/step - loss: 0.1299 - accuracy: 0.9609 - val_loss: 1.8995 - val_accuracy: 0.7192\n",
            "Epoch 97/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.1333 - accuracy: 0.9609 - val_loss: 1.7938 - val_accuracy: 0.7197\n",
            "Epoch 98/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.1333 - accuracy: 0.9603 - val_loss: 1.9760 - val_accuracy: 0.7143\n",
            "Epoch 99/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.1353 - accuracy: 0.9588 - val_loss: 1.7918 - val_accuracy: 0.7154\n",
            "Epoch 100/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.1295 - accuracy: 0.9614 - val_loss: 1.9532 - val_accuracy: 0.7159\n",
            "Epoch 101/200\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.1380 - accuracy: 0.9593 - val_loss: 1.8349 - val_accuracy: 0.7201\n",
            "Epoch 102/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.1401 - accuracy: 0.9586 - val_loss: 1.8475 - val_accuracy: 0.7227\n",
            "Epoch 103/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.1329 - accuracy: 0.9603 - val_loss: 1.8212 - val_accuracy: 0.7127\n",
            "Epoch 104/200\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.1289 - accuracy: 0.9613 - val_loss: 1.7416 - val_accuracy: 0.7126\n",
            "Epoch 105/200\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.1355 - accuracy: 0.9584 - val_loss: 2.1103 - val_accuracy: 0.7031\n",
            "Epoch 106/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.1305 - accuracy: 0.9623 - val_loss: 2.0899 - val_accuracy: 0.7165\n",
            "Epoch 107/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.1302 - accuracy: 0.9606 - val_loss: 1.9568 - val_accuracy: 0.7196\n",
            "Epoch 108/200\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.1321 - accuracy: 0.9613 - val_loss: 1.9332 - val_accuracy: 0.7145\n",
            "Epoch 109/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.1326 - accuracy: 0.9615 - val_loss: 2.0826 - val_accuracy: 0.7108\n",
            "Epoch 110/200\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.1359 - accuracy: 0.9602 - val_loss: 1.7940 - val_accuracy: 0.7171\n",
            "Epoch 111/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.1241 - accuracy: 0.9632 - val_loss: 1.8923 - val_accuracy: 0.7191\n",
            "Epoch 112/200\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.1292 - accuracy: 0.9620 - val_loss: 1.9265 - val_accuracy: 0.7052\n",
            "Epoch 113/200\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.1336 - accuracy: 0.9609 - val_loss: 1.9235 - val_accuracy: 0.7153\n",
            "Epoch 114/200\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.1336 - accuracy: 0.9615 - val_loss: 1.9831 - val_accuracy: 0.7214\n",
            "Epoch 115/200\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1288 - accuracy: 0.9635 - val_loss: 1.8003 - val_accuracy: 0.7163\n",
            "Epoch 116/200\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.1276 - accuracy: 0.9625 - val_loss: 2.2833 - val_accuracy: 0.7015\n",
            "Epoch 117/200\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.1231 - accuracy: 0.9635 - val_loss: 1.8832 - val_accuracy: 0.7181\n",
            "Epoch 118/200\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1312 - accuracy: 0.9609 - val_loss: 1.9164 - val_accuracy: 0.7113\n",
            "Epoch 119/200\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1245 - accuracy: 0.9633 - val_loss: 2.0577 - val_accuracy: 0.7183\n",
            "Epoch 120/200\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.1267 - accuracy: 0.9640 - val_loss: 1.9937 - val_accuracy: 0.7168\n",
            "Epoch 121/200\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.1264 - accuracy: 0.9627 - val_loss: 1.9432 - val_accuracy: 0.7214\n",
            "Epoch 122/200\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.1288 - accuracy: 0.9618 - val_loss: 1.8622 - val_accuracy: 0.7182\n",
            "Epoch 123/200\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1296 - accuracy: 0.9635 - val_loss: 1.9232 - val_accuracy: 0.7136\n",
            "Epoch 124/200\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1244 - accuracy: 0.9629 - val_loss: 2.0766 - val_accuracy: 0.7124\n",
            "Epoch 125/200\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.1175 - accuracy: 0.9660 - val_loss: 2.1188 - val_accuracy: 0.7172\n",
            "Epoch 126/200\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.1349 - accuracy: 0.9615 - val_loss: 2.1531 - val_accuracy: 0.7106\n",
            "Epoch 127/200\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.1346 - accuracy: 0.9629 - val_loss: 1.8421 - val_accuracy: 0.7155\n",
            "Epoch 128/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.1257 - accuracy: 0.9645 - val_loss: 1.9611 - val_accuracy: 0.7171\n",
            "Epoch 129/200\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.1175 - accuracy: 0.9658 - val_loss: 2.3650 - val_accuracy: 0.7109\n",
            "Epoch 130/200\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1262 - accuracy: 0.9629 - val_loss: 1.8661 - val_accuracy: 0.7164\n",
            "Epoch 131/200\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.1419 - accuracy: 0.9597 - val_loss: 2.3408 - val_accuracy: 0.7058\n",
            "Epoch 132/200\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.1240 - accuracy: 0.9635 - val_loss: 1.9204 - val_accuracy: 0.7181\n",
            "Epoch 133/200\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.1298 - accuracy: 0.9629 - val_loss: 2.0519 - val_accuracy: 0.7128\n",
            "Epoch 134/200\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.1241 - accuracy: 0.9647 - val_loss: 2.2426 - val_accuracy: 0.7228\n",
            "Epoch 135/200\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1239 - accuracy: 0.9651 - val_loss: 2.0006 - val_accuracy: 0.7061\n",
            "Epoch 136/200\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1309 - accuracy: 0.9620 - val_loss: 2.0153 - val_accuracy: 0.7126\n",
            "Epoch 137/200\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.1253 - accuracy: 0.9632 - val_loss: 2.1330 - val_accuracy: 0.7169\n",
            "Epoch 138/200\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1292 - accuracy: 0.9635 - val_loss: 2.1021 - val_accuracy: 0.7234\n",
            "Epoch 139/200\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.1224 - accuracy: 0.9658 - val_loss: 1.7278 - val_accuracy: 0.7096\n",
            "Epoch 140/200\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1220 - accuracy: 0.9644 - val_loss: 2.1299 - val_accuracy: 0.7072\n",
            "Epoch 141/200\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.1251 - accuracy: 0.9636 - val_loss: 2.0792 - val_accuracy: 0.7164\n",
            "Epoch 142/200\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1186 - accuracy: 0.9661 - val_loss: 2.4441 - val_accuracy: 0.7104\n",
            "Epoch 143/200\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.1293 - accuracy: 0.9645 - val_loss: 1.9205 - val_accuracy: 0.7061\n",
            "Epoch 144/200\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.1289 - accuracy: 0.9633 - val_loss: 2.1243 - val_accuracy: 0.7080\n",
            "Epoch 145/200\n",
            "1250/1250 [==============================] - 9s 7ms/step - loss: 0.1241 - accuracy: 0.9646 - val_loss: 2.1913 - val_accuracy: 0.7157\n",
            "Epoch 146/200\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.1250 - accuracy: 0.9649 - val_loss: 2.0504 - val_accuracy: 0.7195\n",
            "Epoch 147/200\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1212 - accuracy: 0.9659 - val_loss: 2.1275 - val_accuracy: 0.7109\n",
            "Epoch 148/200\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.1222 - accuracy: 0.9649 - val_loss: 2.1503 - val_accuracy: 0.7159\n",
            "Epoch 149/200\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.1208 - accuracy: 0.9660 - val_loss: 2.0854 - val_accuracy: 0.7109\n",
            "Epoch 150/200\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1317 - accuracy: 0.9640 - val_loss: 1.9657 - val_accuracy: 0.7137\n",
            "Epoch 151/200\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1204 - accuracy: 0.9658 - val_loss: 2.0890 - val_accuracy: 0.7138\n",
            "Epoch 152/200\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.1294 - accuracy: 0.9650 - val_loss: 2.3101 - val_accuracy: 0.7128\n",
            "Epoch 153/200\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.1241 - accuracy: 0.9651 - val_loss: 2.2747 - val_accuracy: 0.7213\n",
            "Epoch 154/200\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.1187 - accuracy: 0.9667 - val_loss: 1.9922 - val_accuracy: 0.7119\n",
            "Epoch 155/200\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.1264 - accuracy: 0.9649 - val_loss: 2.1531 - val_accuracy: 0.7143\n",
            "Epoch 156/200\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.1215 - accuracy: 0.9667 - val_loss: 2.2960 - val_accuracy: 0.7138\n",
            "Epoch 157/200\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.1285 - accuracy: 0.9661 - val_loss: 2.0904 - val_accuracy: 0.7196\n",
            "Epoch 158/200\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1238 - accuracy: 0.9658 - val_loss: 2.2666 - val_accuracy: 0.7108\n",
            "Epoch 159/200\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1239 - accuracy: 0.9651 - val_loss: 2.3752 - val_accuracy: 0.7187\n",
            "Epoch 160/200\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.1270 - accuracy: 0.9650 - val_loss: 2.2879 - val_accuracy: 0.7181\n",
            "Epoch 161/200\n",
            "1250/1250 [==============================] - 11s 8ms/step - loss: 0.1197 - accuracy: 0.9658 - val_loss: 2.3069 - val_accuracy: 0.7219\n",
            "Epoch 162/200\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.1253 - accuracy: 0.9657 - val_loss: 2.2900 - val_accuracy: 0.7021\n",
            "Epoch 163/200\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.1227 - accuracy: 0.9656 - val_loss: 2.3051 - val_accuracy: 0.7129\n",
            "Epoch 164/200\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1128 - accuracy: 0.9678 - val_loss: 2.3571 - val_accuracy: 0.7096\n",
            "Epoch 165/200\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.1304 - accuracy: 0.9637 - val_loss: 2.1985 - val_accuracy: 0.7174\n",
            "Epoch 166/200\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.1263 - accuracy: 0.9651 - val_loss: 2.0582 - val_accuracy: 0.7165\n",
            "Epoch 167/200\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1269 - accuracy: 0.9666 - val_loss: 2.4052 - val_accuracy: 0.7210\n",
            "Epoch 168/200\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.1229 - accuracy: 0.9663 - val_loss: 2.2656 - val_accuracy: 0.7166\n",
            "Epoch 169/200\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1174 - accuracy: 0.9674 - val_loss: 2.3060 - val_accuracy: 0.7209\n",
            "Epoch 170/200\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.1152 - accuracy: 0.9675 - val_loss: 2.1613 - val_accuracy: 0.7151\n",
            "Epoch 171/200\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.1277 - accuracy: 0.9648 - val_loss: 1.8698 - val_accuracy: 0.7116\n",
            "Epoch 172/200\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1302 - accuracy: 0.9643 - val_loss: 2.2174 - val_accuracy: 0.7123\n",
            "Epoch 173/200\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1166 - accuracy: 0.9682 - val_loss: 1.9781 - val_accuracy: 0.7087\n",
            "Epoch 174/200\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.1250 - accuracy: 0.9650 - val_loss: 2.3271 - val_accuracy: 0.7180\n",
            "Epoch 175/200\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.1237 - accuracy: 0.9668 - val_loss: 2.1607 - val_accuracy: 0.7146\n",
            "Epoch 176/200\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1135 - accuracy: 0.9676 - val_loss: 2.0220 - val_accuracy: 0.7145\n",
            "Epoch 177/200\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.1285 - accuracy: 0.9656 - val_loss: 1.9353 - val_accuracy: 0.7090\n",
            "Epoch 178/200\n",
            "1250/1250 [==============================] - 10s 8ms/step - loss: 0.1264 - accuracy: 0.9663 - val_loss: 1.9069 - val_accuracy: 0.7187\n",
            "Epoch 179/200\n",
            "1250/1250 [==============================] - 9s 8ms/step - loss: 0.1201 - accuracy: 0.9660 - val_loss: 2.5611 - val_accuracy: 0.7149\n",
            "Epoch 180/200\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.1261 - accuracy: 0.9664 - val_loss: 2.2244 - val_accuracy: 0.7161\n",
            "Epoch 181/200\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.1272 - accuracy: 0.9651 - val_loss: 2.0556 - val_accuracy: 0.7137\n",
            "Epoch 182/200\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1198 - accuracy: 0.9682 - val_loss: 2.1666 - val_accuracy: 0.7174\n",
            "Epoch 183/200\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1196 - accuracy: 0.9671 - val_loss: 2.2569 - val_accuracy: 0.7096\n",
            "Epoch 184/200\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.1328 - accuracy: 0.9638 - val_loss: 1.8870 - val_accuracy: 0.7113\n",
            "Epoch 185/200\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1129 - accuracy: 0.9679 - val_loss: 2.3399 - val_accuracy: 0.7144\n",
            "Epoch 186/200\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.1146 - accuracy: 0.9682 - val_loss: 2.6154 - val_accuracy: 0.7221\n",
            "Epoch 187/200\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.1199 - accuracy: 0.9681 - val_loss: 2.2052 - val_accuracy: 0.7157\n",
            "Epoch 188/200\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1243 - accuracy: 0.9654 - val_loss: 2.6548 - val_accuracy: 0.7217\n",
            "Epoch 189/200\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.1242 - accuracy: 0.9663 - val_loss: 1.9904 - val_accuracy: 0.7130\n",
            "Epoch 190/200\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1288 - accuracy: 0.9658 - val_loss: 2.2598 - val_accuracy: 0.7160\n",
            "Epoch 191/200\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1194 - accuracy: 0.9673 - val_loss: 2.4241 - val_accuracy: 0.7143\n",
            "Epoch 192/200\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.1291 - accuracy: 0.9653 - val_loss: 2.0554 - val_accuracy: 0.7179\n",
            "Epoch 193/200\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.1208 - accuracy: 0.9671 - val_loss: 2.1951 - val_accuracy: 0.7145\n",
            "Epoch 194/200\n",
            "1250/1250 [==============================] - 9s 8ms/step - loss: 0.1159 - accuracy: 0.9686 - val_loss: 2.7154 - val_accuracy: 0.7145\n",
            "Epoch 195/200\n",
            "1250/1250 [==============================] - 11s 9ms/step - loss: 0.1147 - accuracy: 0.9684 - val_loss: 2.3175 - val_accuracy: 0.7154\n",
            "Epoch 196/200\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.1271 - accuracy: 0.9661 - val_loss: 2.2933 - val_accuracy: 0.7158\n",
            "Epoch 197/200\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.1164 - accuracy: 0.9690 - val_loss: 2.6149 - val_accuracy: 0.7041\n",
            "Epoch 198/200\n",
            "1250/1250 [==============================] - 8s 7ms/step - loss: 0.1154 - accuracy: 0.9680 - val_loss: 2.3417 - val_accuracy: 0.7162\n",
            "Epoch 199/200\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.1261 - accuracy: 0.9662 - val_loss: 2.2362 - val_accuracy: 0.7107\n",
            "Epoch 200/200\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1111 - accuracy: 0.9699 - val_loss: 2.5720 - val_accuracy: 0.7161\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f2208d566b0>"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jC9FcNBAST-n",
        "outputId": "5ae27136-959b-4dc2-f5f0-ad8111a67083"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 2.6676 - accuracy: 0.7145\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Evaluate the model\n",
        "evaluation_results = model.evaluate(x_test, y_test)\n",
        "#print(\"Test Loss:\", evaluation_results[0])\n",
        "#print(\"Test Accuracy:\", evaluation_results[1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluate the model on the test data\n",
        "predictions = model.predict(x_test)\n",
        "predicted_labels = tf.argmax(predictions, axis=1)\n",
        "true_labels = tf.argmax(y_test, axis=1)\n",
        "\n",
        "# Classification Report\n",
        "report = classification_report(true_labels, predicted_labels, target_names=[str(i) for i in range(10)])\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuRApThRwBNG",
        "outputId": "c369f6d8-7abb-4137-9864-14dc63e9c937"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.69      0.74      1000\n",
            "           1       0.88      0.80      0.84      1000\n",
            "           2       0.61      0.63      0.62      1000\n",
            "           3       0.52      0.55      0.53      1000\n",
            "           4       0.62      0.70      0.66      1000\n",
            "           5       0.61      0.64      0.63      1000\n",
            "           6       0.79      0.78      0.79      1000\n",
            "           7       0.77      0.74      0.75      1000\n",
            "           8       0.77      0.84      0.80      1000\n",
            "           9       0.84      0.78      0.81      1000\n",
            "\n",
            "    accuracy                           0.71     10000\n",
            "   macro avg       0.72      0.71      0.72     10000\n",
            "weighted avg       0.72      0.71      0.72     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPJoUmHVxUGn",
        "outputId": "c015a15a-68be-440a-95e9-ea784b2444f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_34 (Conv2D)          (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " conv2d_35 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_21 (MaxPooli  (None, 16, 16, 32)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_36 (Conv2D)          (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_37 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_22 (MaxPooli  (None, 8, 8, 64)          0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_11 (Flatten)        (None, 4096)              0         \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 128)               524416    \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 591274 (2.26 MB)\n",
            "Trainable params: 591274 (2.26 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Compile the model with adjusted learning rate and other hyperparameters\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "-JtQ0nRnxZa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Compile the model with adjusted learning rate and other hyperparameters\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model for more epochs\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=32, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdoYBWjsxuqx",
        "outputId": "14b3bcb7-eefa-484a-92bf-7ac21fee04a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1250/1250 [==============================] - 8s 5ms/step - loss: 2.3028 - accuracy: 0.0980 - val_loss: 2.3029 - val_accuracy: 0.0977\n",
            "Epoch 2/5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3028 - accuracy: 0.0981 - val_loss: 2.3028 - val_accuracy: 0.0977\n",
            "Epoch 3/5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3028 - accuracy: 0.0965 - val_loss: 2.3027 - val_accuracy: 0.0952\n",
            "Epoch 4/5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3028 - accuracy: 0.0980 - val_loss: 2.3027 - val_accuracy: 0.0952\n",
            "Epoch 5/5\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 2.3028 - accuracy: 0.0987 - val_loss: 2.3026 - val_accuracy: 0.1022\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f2212cabbe0>"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V0cA0ebEy2LV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}